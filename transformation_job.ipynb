{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "import sys\nimport unicodedata\nimport uuid\n\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.functions import col, lit, udf, regexp_replace\nfrom pyspark.sql.types import StringType\nfrom awsglue.context import GlueContext\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom awsglue.job import Job\n\n# Inicializar Spark y Glue Context\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n\n# Parámetros de entrada\nargs = getResolvedOptions(sys.argv, ['JOB_NAME', 's3_input_path', 's3_output_path'])\njob.init(args['JOB_NAME'], args)\n\n# Cargar los datos desde S3\ndf = spark.read.csv(args['s3_input_path'], header=True, inferSchema=True)\n\n# Función para quitar tildes\ndef quitar_tildes(texto):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', texto) \n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Registrar la función como UDF\nquitar_tildes_udf = udf(quitar_tildes, StringType())\n\n# Aplicar la función para eliminar tildes en la columna 'departamento'\ndf = df.withColumn('departamento', quitar_tildes_udf(col('departamento')))\n\n# Lista de departamentos válidos en Colombia\ndepartamentos_colombia = [\n    'AMAZONAS', 'ANTIOQUIA', 'ARAUCA', 'ATLANTICO', 'BOLIVAR', 'BOYACA', 'CALDAS', 'CAQUETA', 'CASANARE', 'CAUCA',\n    'CESAR', 'CHOCO', 'CORDOBA', 'CUNDINAMARCA', 'GUAINIA', 'GUAVIARE', 'HUILA', 'LA GUAJIRA', 'MAGDALENA', 'META',\n    'NARINO', 'NORTE DE SANTANDER', 'PUTUMAYO', 'QUINDIO', 'RISARALDA', 'SAN ANDRES Y PROVIDENCIA', 'SANTANDER',\n    'SUCRE', 'TOLIMA', 'VALLE DEL CAUCA', 'VAUPES', 'VICHADA'\n]\n\n# Filtrar solo los departamentos válidos\ndf = df.filter(df['departamento'].isin(departamentos_colombia))\n\n# Renombrar columnas\ndf = (\n    df.withColumnRenamed(\"armas medios\", \"armas_medios\")\n      .withColumnRenamed(\"fecha hecho\", \"fecha_hecho\")\n)\n\n# Eliminar columna no deseada\ndf = df.drop(\"CODIGO DANE\")\n\n# Eliminar filas con valores nulos\ndf = df.dropna()\n\n# Agregar una columna 'id' con UUID (igual para todas las filas, si quieres uno único por fila, usa un UDF con uuid4())\ndf = df.withColumn('id', lit(str(uuid.uuid4())))\n\n# Limpiar texto en la columna 'municipio'\ndf = df.withColumn('municipio', regexp_replace(col('municipio'), r'\\(CT\\)', ''))\n\n# Guardar el DataFrame en S3 en formato Parquet\ndf.write.mode('overwrite').parquet(args['s3_output_path'])\n\n# Finalizar el trabajo\njob.commit()\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.8 \nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nSession ID: 54dba1bc-e3df-48bc-a82d-2598ebe81a3f\nApplying the following default arguments:\n--glue_kernel_version 1.0.8\n--enable-glue-datacatalog true\nWaiting for session 54dba1bc-e3df-48bc-a82d-2598ebe81a3f to get into ready status...\nSession 54dba1bc-e3df-48bc-a82d-2598ebe81a3f has been created.\nGlueArgumentError: the following arguments are required: --JOB_NAME, --s3_input_path, --s3_output_path_medellin, --s3_output_path_otros\n",
					"output_type": "stream"
				}
			]
		}
	]
}